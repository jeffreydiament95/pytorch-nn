{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train dataset for mean calculation\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1307), tensor(0.3081))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute mean and std of the train dataset\n",
    "mean = train_dataset.data.float().mean() / 255\n",
    "std = train_dataset.data.float().std() / 255\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformation to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(mean,), std=(std,))\n",
    "])\n",
    "\n",
    "# Load the train and test datasets with normalization. these normalizations are applied to the images when they are loaded\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-5.6966e-08), tensor(1.0000))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the mean and standard deviation of the normalized dataset as a sanity check\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "data = next(iter(train_loader))\n",
    "\n",
    "# data[0] is the tensor containing all the images\n",
    "# data[1] is the tensor containing all the labels\n",
    "mean = data[0].mean()\n",
    "std = data[0].std()\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataLoader to load the data in batches\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=9, shuffle=True)\n",
    "\n",
    "# Get a batch of images from the DataLoader\n",
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "# Create a grid of images and display them\n",
    "fig, axs = plt.subplots(3, 3, figsize=(6, 6))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    # Convert the tensor image to a numpy array and transpose it\n",
    "    image = np.transpose(image.numpy(), (1, 2, 0))\n",
    "\n",
    "    # Display the image on the corresponding subplot\n",
    "    axs[i].imshow(image[:, :, 0], cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.089\n",
      "[1,   200] loss: 0.423\n",
      "[1,   300] loss: 0.333\n",
      "[1,   400] loss: 0.255\n",
      "[1,   500] loss: 0.251\n",
      "[1,   600] loss: 0.220\n",
      "[1,   700] loss: 0.217\n",
      "[1,   800] loss: 0.204\n",
      "[1,   900] loss: 0.163\n",
      "[2,   100] loss: 0.138\n",
      "[2,   200] loss: 0.151\n",
      "[2,   300] loss: 0.135\n",
      "[2,   400] loss: 0.125\n",
      "[2,   500] loss: 0.129\n",
      "[2,   600] loss: 0.126\n",
      "[2,   700] loss: 0.124\n",
      "[2,   800] loss: 0.125\n",
      "[2,   900] loss: 0.100\n",
      "[3,   100] loss: 0.086\n",
      "[3,   200] loss: 0.099\n",
      "[3,   300] loss: 0.086\n",
      "[3,   400] loss: 0.083\n",
      "[3,   500] loss: 0.083\n",
      "[3,   600] loss: 0.086\n",
      "[3,   700] loss: 0.086\n",
      "[3,   800] loss: 0.090\n",
      "[3,   900] loss: 0.070\n",
      "[4,   100] loss: 0.061\n",
      "[4,   200] loss: 0.067\n",
      "[4,   300] loss: 0.063\n",
      "[4,   400] loss: 0.057\n",
      "[4,   500] loss: 0.059\n",
      "[4,   600] loss: 0.063\n",
      "[4,   700] loss: 0.064\n",
      "[4,   800] loss: 0.065\n",
      "[4,   900] loss: 0.052\n",
      "[5,   100] loss: 0.044\n",
      "[5,   200] loss: 0.049\n",
      "[5,   300] loss: 0.045\n",
      "[5,   400] loss: 0.045\n",
      "[5,   500] loss: 0.046\n",
      "[5,   600] loss: 0.047\n",
      "[5,   700] loss: 0.046\n",
      "[5,   800] loss: 0.045\n",
      "[5,   900] loss: 0.038\n",
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network and other training parameters\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 5\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Evaluate the neural network on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
       "        0.0010, 0.0010, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0011, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012,\n",
       "        0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012,\n",
       "        0.0012, 0.0012, 0.0012, 0.0012, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013,\n",
       "        0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013,\n",
       "        0.0013, 0.0013, 0.0013, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014,\n",
       "        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014,\n",
       "        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n",
       "        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0016, 0.0016, 0.0016,\n",
       "        0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016,\n",
       "        0.0016, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017,\n",
       "        0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0018, 0.0018, 0.0018, 0.0018,\n",
       "        0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0019,\n",
       "        0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019,\n",
       "        0.0019, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
       "        0.0020, 0.0020, 0.0020, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
       "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0022, 0.0022, 0.0022, 0.0022,\n",
       "        0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0023, 0.0023, 0.0023, 0.0023,\n",
       "        0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0024, 0.0024, 0.0024,\n",
       "        0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0025, 0.0025, 0.0025,\n",
       "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0026, 0.0026, 0.0026,\n",
       "        0.0026, 0.0026, 0.0026, 0.0026, 0.0026, 0.0027, 0.0027, 0.0027, 0.0027,\n",
       "        0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0028, 0.0028, 0.0028,\n",
       "        0.0028, 0.0028, 0.0028, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
       "        0.0029, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0031,\n",
       "        0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0032, 0.0032,\n",
       "        0.0032, 0.0032, 0.0032, 0.0032, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "        0.0033, 0.0033, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0035,\n",
       "        0.0035, 0.0035, 0.0035, 0.0035, 0.0035, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "        0.0036, 0.0036, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0038,\n",
       "        0.0038, 0.0038, 0.0038, 0.0038, 0.0038, 0.0039, 0.0039, 0.0039, 0.0039,\n",
       "        0.0039, 0.0039, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0041, 0.0041,\n",
       "        0.0041, 0.0041, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043,\n",
       "        0.0043, 0.0043, 0.0043, 0.0043, 0.0044, 0.0044, 0.0044, 0.0044, 0.0044,\n",
       "        0.0045, 0.0045, 0.0045, 0.0045, 0.0045, 0.0046, 0.0046, 0.0046, 0.0046,\n",
       "        0.0046, 0.0047, 0.0047, 0.0047, 0.0047, 0.0047, 0.0048, 0.0048, 0.0048,\n",
       "        0.0048, 0.0049, 0.0049, 0.0049, 0.0049, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0051, 0.0051, 0.0051, 0.0051, 0.0052, 0.0052, 0.0052, 0.0052,\n",
       "        0.0053, 0.0053, 0.0053, 0.0053, 0.0054, 0.0054, 0.0054, 0.0054, 0.0055,\n",
       "        0.0055, 0.0055, 0.0055, 0.0056, 0.0056, 0.0056, 0.0056, 0.0057, 0.0057,\n",
       "        0.0057, 0.0057, 0.0058, 0.0058, 0.0058, 0.0058, 0.0059, 0.0059, 0.0059,\n",
       "        0.0060, 0.0060, 0.0060, 0.0060, 0.0061, 0.0061, 0.0061, 0.0061, 0.0062,\n",
       "        0.0062, 0.0062, 0.0063, 0.0063, 0.0063, 0.0064, 0.0064, 0.0064, 0.0064,\n",
       "        0.0065, 0.0065, 0.0065, 0.0066, 0.0066, 0.0066, 0.0067, 0.0067, 0.0067,\n",
       "        0.0067, 0.0068, 0.0068, 0.0068, 0.0069, 0.0069, 0.0069, 0.0070, 0.0070,\n",
       "        0.0070, 0.0071, 0.0071, 0.0071, 0.0072, 0.0072, 0.0072, 0.0073, 0.0073,\n",
       "        0.0073, 0.0074, 0.0074, 0.0074, 0.0075, 0.0075, 0.0075, 0.0076, 0.0076,\n",
       "        0.0076, 0.0077, 0.0077, 0.0077, 0.0078, 0.0078, 0.0079, 0.0079, 0.0079,\n",
       "        0.0080, 0.0080, 0.0080, 0.0081, 0.0081, 0.0081, 0.0082, 0.0082, 0.0083,\n",
       "        0.0083, 0.0083, 0.0084, 0.0084, 0.0085, 0.0085, 0.0085, 0.0086, 0.0086,\n",
       "        0.0086, 0.0087, 0.0087, 0.0088, 0.0088, 0.0089, 0.0089, 0.0089, 0.0090,\n",
       "        0.0090, 0.0091, 0.0091, 0.0091, 0.0092, 0.0092, 0.0093, 0.0093, 0.0094,\n",
       "        0.0094, 0.0094, 0.0095, 0.0095, 0.0096, 0.0096, 0.0097, 0.0097, 0.0097,\n",
       "        0.0098, 0.0098, 0.0099, 0.0099, 0.0100, 0.0100, 0.0101, 0.0101, 0.0102,\n",
       "        0.0102, 0.0103, 0.0103, 0.0104, 0.0104, 0.0104, 0.0105, 0.0105, 0.0106,\n",
       "        0.0106, 0.0107, 0.0107, 0.0108, 0.0108, 0.0109, 0.0109, 0.0110, 0.0110,\n",
       "        0.0111, 0.0111, 0.0112, 0.0112, 0.0113, 0.0114, 0.0114, 0.0115, 0.0115,\n",
       "        0.0116, 0.0116, 0.0117, 0.0117, 0.0118, 0.0118, 0.0119, 0.0119, 0.0120,\n",
       "        0.0121, 0.0121, 0.0122, 0.0122, 0.0123, 0.0123, 0.0124, 0.0124, 0.0125,\n",
       "        0.0126, 0.0126, 0.0127, 0.0127, 0.0128, 0.0129, 0.0129, 0.0130, 0.0130,\n",
       "        0.0131, 0.0132, 0.0132, 0.0133, 0.0133, 0.0134, 0.0135, 0.0135, 0.0136,\n",
       "        0.0137, 0.0137, 0.0138, 0.0138, 0.0139, 0.0140, 0.0140, 0.0141, 0.0142,\n",
       "        0.0142, 0.0143, 0.0144, 0.0144, 0.0145, 0.0146, 0.0146, 0.0147, 0.0148,\n",
       "        0.0148, 0.0149, 0.0150, 0.0150, 0.0151, 0.0152, 0.0152, 0.0153, 0.0154,\n",
       "        0.0155, 0.0155, 0.0156, 0.0157, 0.0157, 0.0158, 0.0159, 0.0160, 0.0160,\n",
       "        0.0161, 0.0162, 0.0163, 0.0163, 0.0164, 0.0165, 0.0166, 0.0166, 0.0167,\n",
       "        0.0168, 0.0169, 0.0170, 0.0170, 0.0171, 0.0172, 0.0173, 0.0173, 0.0174,\n",
       "        0.0175, 0.0176, 0.0177, 0.0178, 0.0178, 0.0179, 0.0180, 0.0181, 0.0182,\n",
       "        0.0182, 0.0183, 0.0184, 0.0185, 0.0186, 0.0187, 0.0188, 0.0188, 0.0189,\n",
       "        0.0190, 0.0191, 0.0192, 0.0193, 0.0194, 0.0195, 0.0196, 0.0196, 0.0197,\n",
       "        0.0198, 0.0199, 0.0200, 0.0201, 0.0202, 0.0203, 0.0204, 0.0205, 0.0206,\n",
       "        0.0207, 0.0208, 0.0209, 0.0210, 0.0211, 0.0212, 0.0212, 0.0213, 0.0214,\n",
       "        0.0215, 0.0216, 0.0217, 0.0218, 0.0219, 0.0220, 0.0221, 0.0223, 0.0224,\n",
       "        0.0225, 0.0226, 0.0227, 0.0228, 0.0229, 0.0230, 0.0231, 0.0232, 0.0233,\n",
       "        0.0234, 0.0235, 0.0236, 0.0237, 0.0238, 0.0240, 0.0241, 0.0242, 0.0243,\n",
       "        0.0244, 0.0245, 0.0246, 0.0247, 0.0249, 0.0250, 0.0251, 0.0252, 0.0253,\n",
       "        0.0254, 0.0256, 0.0257, 0.0258, 0.0259, 0.0260, 0.0261, 0.0263, 0.0264,\n",
       "        0.0265, 0.0266, 0.0268, 0.0269, 0.0270, 0.0271, 0.0273, 0.0274, 0.0275,\n",
       "        0.0276, 0.0278, 0.0279, 0.0280, 0.0281, 0.0283, 0.0284, 0.0285, 0.0287,\n",
       "        0.0288, 0.0289, 0.0291, 0.0292, 0.0293, 0.0295, 0.0296, 0.0297, 0.0299,\n",
       "        0.0300, 0.0302, 0.0303, 0.0304, 0.0306, 0.0307, 0.0309, 0.0310, 0.0312,\n",
       "        0.0313, 0.0314, 0.0316, 0.0317, 0.0319, 0.0320, 0.0322, 0.0323, 0.0325,\n",
       "        0.0326, 0.0328, 0.0329, 0.0331, 0.0332, 0.0334, 0.0335, 0.0337, 0.0338,\n",
       "        0.0340, 0.0342, 0.0343, 0.0345, 0.0346, 0.0348, 0.0350, 0.0351, 0.0353,\n",
       "        0.0354, 0.0356, 0.0358, 0.0359, 0.0361, 0.0363, 0.0364, 0.0366, 0.0368,\n",
       "        0.0369, 0.0371, 0.0373, 0.0375, 0.0376, 0.0378, 0.0380, 0.0382, 0.0383,\n",
       "        0.0385, 0.0387, 0.0389, 0.0390, 0.0392, 0.0394, 0.0396, 0.0398, 0.0400,\n",
       "        0.0401, 0.0403, 0.0405, 0.0407, 0.0409, 0.0411, 0.0413, 0.0415, 0.0417,\n",
       "        0.0418, 0.0420, 0.0422, 0.0424, 0.0426, 0.0428, 0.0430, 0.0432, 0.0434,\n",
       "        0.0436, 0.0438, 0.0440, 0.0442, 0.0444, 0.0446, 0.0448, 0.0450, 0.0453,\n",
       "        0.0455, 0.0457, 0.0459, 0.0461, 0.0463, 0.0465, 0.0467, 0.0470, 0.0472,\n",
       "        0.0474, 0.0476, 0.0478, 0.0480, 0.0483, 0.0485, 0.0487, 0.0489, 0.0492,\n",
       "        0.0494, 0.0496, 0.0499, 0.0501, 0.0503, 0.0505, 0.0508, 0.0510, 0.0513,\n",
       "        0.0515, 0.0517, 0.0520, 0.0522, 0.0524, 0.0527, 0.0529, 0.0532, 0.0534,\n",
       "        0.0537, 0.0539, 0.0542, 0.0544, 0.0547, 0.0549, 0.0552, 0.0554, 0.0557,\n",
       "        0.0559, 0.0562, 0.0565, 0.0567, 0.0570, 0.0572, 0.0575, 0.0578, 0.0580,\n",
       "        0.0583, 0.0586, 0.0589, 0.0591, 0.0594, 0.0597, 0.0599, 0.0602, 0.0605,\n",
       "        0.0608, 0.0611, 0.0613, 0.0616, 0.0619, 0.0622, 0.0625, 0.0628, 0.0631,\n",
       "        0.0634, 0.0637, 0.0639, 0.0642, 0.0645, 0.0648, 0.0651, 0.0654, 0.0657,\n",
       "        0.0660, 0.0663, 0.0667, 0.0670, 0.0673, 0.0676, 0.0679, 0.0682, 0.0685,\n",
       "        0.0688, 0.0692, 0.0695, 0.0698, 0.0701, 0.0704, 0.0708, 0.0711, 0.0714,\n",
       "        0.0718, 0.0721, 0.0724, 0.0728, 0.0731, 0.0734, 0.0738, 0.0741, 0.0745,\n",
       "        0.0748, 0.0751, 0.0755, 0.0758, 0.0762, 0.0765, 0.0769, 0.0772, 0.0776,\n",
       "        0.0780, 0.0783, 0.0787, 0.0790, 0.0794, 0.0798, 0.0802, 0.0805, 0.0809,\n",
       "        0.0813, 0.0816, 0.0820, 0.0824, 0.0828, 0.0832, 0.0835, 0.0839, 0.0843,\n",
       "        0.0847, 0.0851, 0.0855, 0.0859, 0.0863, 0.0867, 0.0871, 0.0875, 0.0879,\n",
       "        0.0883, 0.0887, 0.0891, 0.0895, 0.0899, 0.0904, 0.0908, 0.0912, 0.0916,\n",
       "        0.0920, 0.0925, 0.0929, 0.0933, 0.0938, 0.0942, 0.0946, 0.0951, 0.0955,\n",
       "        0.0959, 0.0964, 0.0968, 0.0973, 0.0977, 0.0982, 0.0986, 0.0991, 0.0995,\n",
       "        0.1000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lre = torch.linspace(-3, -1, 1000)\n",
    "lrs = 10 ** lre\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
